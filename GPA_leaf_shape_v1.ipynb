{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5036c539",
   "metadata": {},
   "source": [
    "# Leaf shape analysis using Generalized Procrustes Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267ecb3",
   "metadata": {},
   "source": [
    "The following is a `jupyter notebook` ([Kluyver et al. 2016](https://ebooks.iospress.nl/doi/10.3233/978-1-61499-649-1-87)) tutorial written using the `python` coding language. Text written in `markdown cells` is used to explain code presented and executed in `coding cells`. This tutorial assumes a working knowledge of `python` and the ability to use `jupyter notebooks`.  \n",
    "\n",
    "If you are new to `python` or do not know how to use `jupyter notebooks`, we recommend that you familiarize yourself with them through a tutorial. For the context of plant biology and leaf shape presented here, we recommend `Plants&Python` ([VanBuren et al., 2022](https://doi.org/10.1093/plcell/koac187)), accessible using this [link](https://plantsandpython.github.io/PlantsAndPython). There you will find instructions for downloading and installing [Anaconda](https://docs.anaconda.com/anaconda/install/) and how to get going with `jupyter notebooks` and `python`.m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bef64a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"page_top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0295b2c",
   "metadata": {},
   "source": [
    "## Sections\n",
    "1. [Loading modules and functions](#Loading_modules_and_functions)\n",
    "2. [Reading in data](#Reading_in_data)\n",
    "\n",
    "    a. [*Capsella bursa-pastoris*](#capsella)\n",
    "    \n",
    "    b. [*Arabidopsis thaliana*](#arabidopsis)\n",
    "    \n",
    "    c. [*Quercus spp*](#oak)\n",
    "    \n",
    "    d. [*Cannabis sativa*](#cannabis)\n",
    "    \n",
    "    e. [*Beta vulgaris*](#sugar_beets)\n",
    "    \n",
    "    f. [*Lobelia spp*](#lobelia)\n",
    "    \n",
    "    g. [*Erythroxylum coca*](#coca)\n",
    "    \n",
    "    h. [*Malus spp*](#apple)\n",
    "    \n",
    "    \n",
    "3. [Plotting pseudo-landmarks](#pseudo_landmarks)\n",
    "4. [Section 4: combine datasets](#combine_datasets)\n",
    "5. [Section 5: Procruestes Analysis and PCA](#pca)\n",
    "6. [Section 6: Save pseudo-landmarked and Procrustes aligned leaves for future use](#save_data)\n",
    "7. [Section 7: Analyze leaf dimensions](#leaf_measurements)\n",
    "8. [Section 8: Explore data - Pairplot of all measured traits](#pair_plot)\n",
    "9. [Color Palette](#color_palette)\n",
    "10. [Section 9: Plotting PCA morphospace](#morphospace)\n",
    "11. [Continuous color - custom](#custom_color)\n",
    "12. [Section 10: Plotting real leaves](#plot_leaves)\n",
    "13. [Section 11: Split datasets for further PCA morphospace plotting](#split_dataset)\n",
    "14. [Section 12: Linear Discriminant Analysis](#LDA)\n",
    "15. [Section 14: Plotting the mean leaf for the entire dataset and each species dataset](#mean_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2f7db",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"Loading_modules_and_functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585d42b",
   "metadata": {},
   "source": [
    "### Section 1: Loading modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### LOAD IN MODULES ###\n",
    "#######################\n",
    "\n",
    "import cv2 # to install on mac: pip install opencv-python\n",
    "from scipy.interpolate import interp1d # for interpolating points\n",
    "from sklearn.decomposition import PCA # for principal component analysis\n",
    "from scipy.spatial import procrustes # for Procrustes analysis\n",
    "from scipy.spatial import ConvexHull # for convex hull\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # for LDA\n",
    "from sklearn.metrics import confusion_matrix # for confusion matrix\n",
    "import os\n",
    "from os import listdir # for retrieving files from directory\n",
    "from os.path import isfile, join # for retrieving files from directory\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "%matplotlib inline\n",
    "import numpy as np # for using arrays\n",
    "import math # for mathematical operations\n",
    "import pandas as pd # for using pandas dataframes\n",
    "import seaborn as sns # for plotting in seaborna\n",
    "import csv\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "### FUNCTIONS ###\n",
    "#################\n",
    "\n",
    "def angle_between(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    define a function to find the angle between 3 points anti-clockwise in degrees, p2 being the vertex\n",
    "    inputs: three angle points, as tuples\n",
    "    output: angle in degrees\n",
    "    \"\"\"\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "    deg1 = (360 + math.degrees(math.atan2(x1 - x2, y1 - y2))) % 360\n",
    "    deg2 = (360 + math.degrees(math.atan2(x3 - x2, y3 - y2))) % 360\n",
    "    return deg2 - deg1 if deg1 <= deg2 else 360 - (deg1 - deg2)\n",
    "\n",
    "def rotate_points(xvals, yvals, degrees):\n",
    "    \"\"\"\"\n",
    "    define a function to rotate 2D x and y coordinate points around the origin\n",
    "    inputs: x and y vals (can take pandas dataframe columns) and the degrees (positive, anticlockwise) to rotate\n",
    "    outputs: rotated and y vals\n",
    "    \"\"\"\n",
    "    angle_to_move = 90-degrees\n",
    "    rads = np.deg2rad(angle_to_move)\n",
    "    \n",
    "    new_xvals = xvals*np.cos(rads)-yvals*np.sin(rads)\n",
    "    new_yvals = xvals*np.sin(rads)+yvals*np.cos(rads)\n",
    "    \n",
    "    return new_xvals, new_yvals\n",
    "\n",
    "def interpolation(x, y, number): \n",
    "    \"\"\"\n",
    "    define a function to return equally spaced, interpolated points for a given polyline\n",
    "    inputs: arrays of x and y values for a polyline, number of points to interpolate\n",
    "    ouputs: interpolated points along the polyline, inclusive of start and end points\n",
    "    \"\"\"\n",
    "    distance = np.cumsum(np.sqrt( np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2 ))\n",
    "    distance = distance/distance[-1]\n",
    "\n",
    "    fx, fy = interp1d( distance, x ), interp1d( distance, y )\n",
    "\n",
    "    alpha = np.linspace(0, 1, number)\n",
    "    x_regular, y_regular = fx(alpha), fy(alpha)\n",
    "    \n",
    "    return x_regular, y_regular\n",
    "\n",
    "def euclid_dist(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    define a function to return the euclidean distance between two points\n",
    "    inputs: x and y values of the two points\n",
    "    output: the eulidean distance\n",
    "    \"\"\"\n",
    "    return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "\n",
    "def poly_area(x,y):\n",
    "    \"\"\"\n",
    "    define a function to calculate the area of a polygon using the shoelace algorithm\n",
    "    inputs: separate numpy arrays of x and y coordinate values\n",
    "    outputs: the area of the polygon\n",
    "    \"\"\"\n",
    "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",
    "\n",
    "def gpa_mean(leaf_arr, landmark_num, dim_num):\n",
    "    \n",
    "    \"\"\"\n",
    "    define a function that given an array of landmark data returns the Generalized Procrustes Analysis mean\n",
    "    inputs: a 3 dimensional array of samples by landmarks by coordinate values, number of landmarks, number of dimensions\n",
    "    output: an array of the Generalized Procrustes Analysis mean shape\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ref_ind = 0 # select arbitrary reference index to calculate procrustes distances to\n",
    "    ref_shape = leaf_arr[ref_ind, :, :] # select the reference shape\n",
    "\n",
    "    mean_diff = 10**(-30) # set a distance between means to stop the algorithm\n",
    "\n",
    "    old_mean = ref_shape # for the first comparison between means, set old_mean to an arbitrary reference shape\n",
    "\n",
    "    d = 1000000 # set d initially arbitraily high\n",
    "\n",
    "    while d > mean_diff: # set boolean criterion for Procrustes distance between mean to stop calculations\n",
    "\n",
    "        arr = np.zeros( ((len(leaf_arr)),landmark_num,dim_num) ) # empty 3D array: # samples, landmarks, coord vals\n",
    "\n",
    "        for i in range(len(leaf_arr)): # for each leaf shape \n",
    "\n",
    "            s1, s2, distance = procrustes(old_mean, leaf_arr[i]) # calculate procrustes adjusted shape to ref for current leaf\n",
    "            arr[i] = s2 # store procrustes adjusted shape to array\n",
    "\n",
    "        new_mean = np.mean(arr, axis=(0)) # calculate mean of all shapes adjusted to reference\n",
    "\n",
    "        s1, s2, d = procrustes(old_mean, new_mean) # calculate procrustes distance of new mean to old mean\n",
    "\n",
    "        old_mean = new_mean # set the old_mean to the new_mea before beginning another iteration\n",
    "\n",
    "    return new_mean\n",
    "\n",
    "def Circularity(shape_arr):\n",
    "    \n",
    "    lines = np.hstack([shape_arr,np.roll(shape_arr,-1,axis=0)])\n",
    "    area = 0.5*abs(sum(x1*y2-x2*y1 for x1,y1,x2,y2 in lines))\n",
    "    \n",
    "    distance = np.cumsum(np.sqrt( np.ediff1d(shape_arr[:,0], to_begin=0)**2 + np.ediff1d(shape_arr[:,1], to_begin=0)**2 ))\n",
    "    perimeter = distance[-1]\n",
    "    \n",
    "    circularity = (4*math.pi*area)/perimeter**2\n",
    "    \n",
    "    return circularity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4aff0",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66a9ac",
   "metadata": {},
   "source": [
    "<a id='#Reading in data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a534cb8",
   "metadata": {},
   "source": [
    "### Section 2: Reading in Data  <a class=\"anchor\" id=\"Reading_in_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfa6a7",
   "metadata": {},
   "source": [
    "If your image data includes only outlines (xy coordinate files) follow subsection 1. If your image data includes only black leaf images printed on white backgound, follow subsection 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10ecf8",
   "metadata": {},
   "source": [
    "##### Subsection 1: Reading in leaf outline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Volumes/TOSHIBA/collab_v3/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbfe7f",
   "metadata": {},
   "source": [
    "##### Subsection 2: Reading in binary leaf image data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98258f",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Change the directory where your files are located. This should be one folder that includes another folder of all images you want to include in your data set and a csv file.\n",
    "2. Import your metadata csv as a pandas dataframe named mdata. The csv file should include these headings: file - the file name for each image, dataset - researcher defined, px_cm - pixels per centimeter, base_x and base_y - the x and y coordinates for the base of each leaf, tip_x and tip_y - the x and y coordinates for the tip of each leaf.\n",
    "3. Upload your images into the \"data_dir\" data directory using the file path for the folder with all of your images files for your dataset. \n",
    "4. Print the mdata dataframe and image file names to check for any errors. Most errors occur at this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e97503",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"capsella\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d10046",
   "metadata": {},
   "source": [
    "### *Capsella bursa-pastoris*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f7274a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "capsella_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/capsella/capsella.csv\") # read in csv\n",
    "\n",
    "capsella_mdata.head() # head data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad157bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(capsella_mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6187c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "### MAKE A LIST OF IMAGE FILE NAMES ###\n",
    "#######################################\n",
    "\n",
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/capsella/capsella_images/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b530d1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pseudo_landmarks\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf765b6d",
   "metadata": {},
   "source": [
    "### Section 3: Place equidistant pseudo-landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a7632",
   "metadata": {},
   "source": [
    "- Read in image in grayscale\n",
    "- Select the contour of the largest object (the leaf)\n",
    "- Interpolate with a high resolution of pseudo-landmarks\n",
    "- Find the base and tip index point on the high resolution contour\n",
    "- Reset the base index to zero\n",
    "- Interpolate each side with desired number of equidistant pseudo-landmarks\n",
    "- Rotate leaves and scale to centimeters\n",
    "- Save pseudo-landmarks scaled to centimeters in an array\n",
    "\n",
    "PARAMETERS AND INDEXING:\n",
    "- `high_res_pts` is an arbitrarily high number of points to initially interpolate\n",
    "- `res` is the desired number of points to interpolate on each side of the leaf\n",
    "- The total number of pseudo-landmarks will be `2*res - 1`\n",
    "- The base index will be `0`\n",
    "- The tip index will be `res-1`\n",
    "- The returned leaves in `cm_arr` are scaled in size to centimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf863fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 1000 \n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "capsella_cm_arr = np.zeros((len(capsella_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(capsella_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = capsella_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(sorted_x_conts[0], \n",
    "                                           sorted_y_conts[0], high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((capsella_mdata[\"base_x\"][lf], capsella_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((capsella_mdata[\"tip_x\"][lf], capsella_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(capsella_mdata[\"px_cm\"][lf])\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    capsella_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebbb51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"capsella_bursa_pastoris_cm_arr\", capsella_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c801ac",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7aa58",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"arabidopsis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02ef7a",
   "metadata": {},
   "source": [
    "### *Arabidopsis thaliana*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602d94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arabidopsis_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/arabidopsis/arabidopsis.csv\") # read in csv\n",
    "\n",
    "arabidopsis_mdata.head() # head data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arabidopsis_mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e933e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "### MAKE A LIST OF IMAGE FILE NAMES ###\n",
    "#######################################\n",
    "\n",
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/arabidopsis/arabidopsis_images/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddebfd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 1000 \n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "arabidopsis_cm_arr = np.zeros((len(arabidopsis_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(arabidopsis_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = arabidopsis_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(sorted_x_conts[0], \n",
    "                                           sorted_y_conts[0], high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((arabidopsis_mdata[\"base_x\"][lf], arabidopsis_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((arabidopsis_mdata[\"tip_x\"][lf], arabidopsis_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(arabidopsis_mdata[\"px_cm\"][lf])\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    arabidopsis_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"arabidopsis_thaliana_cm_arr\", arabidopsis_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915de56",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452700e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"oak\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759de26b",
   "metadata": {},
   "source": [
    "### *Quercus spp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "oak_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/oak/oak.csv\") # read in csv\n",
    "\n",
    "oak_mdata.head() # head data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oak_mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e5dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "### MAKE A LIST OF IMAGE FILE NAMES ###\n",
    "#######################################\n",
    "\n",
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/oak/claire_oak_reprint_111224/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a40aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 1000 \n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "oak_cm_arr = np.zeros((len(oak_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(oak_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = oak_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(sorted_x_conts[0], \n",
    "                                           sorted_y_conts[0], high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((oak_mdata[\"base_x\"][lf], oak_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((oak_mdata[\"tip_x\"][lf], oak_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(oak_mdata[\"px_cm\"][lf])\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    oak_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Quercus_spp_cm_arr\", oak_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7aa9f4",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be67c70",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cannabis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3954504a",
   "metadata": {},
   "source": [
    "### *Cannaibas sativa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e56710",
   "metadata": {},
   "outputs": [],
   "source": [
    "cannibas_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/cannibas/cannibas.csv\") # read in csv\n",
    "\n",
    "cannibas_mdata.head() # head data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e634640",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cannibas_mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb53c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "### MAKE A LIST OF IMAGE FILE NAMES ###\n",
    "#######################################\n",
    "\n",
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/cannibas/cannibas_images/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd872abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 1000 \n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "cannibas_cm_arr = np.zeros((len(cannibas_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(cannibas_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = cannibas_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(sorted_x_conts[0], \n",
    "                                           sorted_y_conts[0], high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((cannibas_mdata[\"base_x\"][lf], cannibas_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((cannibas_mdata[\"tip_x\"][lf], cannibas_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(cannibas_mdata[\"px_cm\"][lf])\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    cannibas_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cannibas_sativa_cm_arr\", cannibas_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d8af9",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295e04a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sugar_beets\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011006b6",
   "metadata": {},
   "source": [
    "### *Beta vulgaris*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e0a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### READ IN METADATA ###\n",
    "########################\n",
    "\n",
    "sugar_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/sugar_beets/sugar_beets.csv\") # read in csv\n",
    "\n",
    "sugar_mdata.head() # head data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sugar_mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0938c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/sugar_beets/LEAF_SCAN_BINARY/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb75b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 10000\n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "sugar_cm_arr = np.zeros((len(sugar_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(sugar_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = sugar_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(np.array(sorted_x_conts[0], dtype=np.float32), \n",
    "                                           np.array(sorted_y_conts[0], dtype=np.float32), high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((sugar_mdata[\"base_x\"][lf], sugar_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((sugar_mdata[\"tip_x\"][lf], sugar_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "    \n",
    "    # calculate leaf area in pixels^2\n",
    "    lf_area_px2 = poly_area(rot_pts[:,0], rot_pts[:,1])\n",
    "    \n",
    "    # get px_cm\n",
    "    px_cm = sugar_mdata[\"px_cm\"][lf]\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(px_cm)\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    sugar_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"beta_vulgaris_cm_arr\", sugar_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e460c9",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8195f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"lobelia\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914092f",
   "metadata": {},
   "source": [
    "### *Lobelia spp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d79374",
   "metadata": {},
   "outputs": [],
   "source": [
    "lobelia_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/lobelia/lobelia.csv\") # read in csv\n",
    "\n",
    "lobelia_mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b9e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "### MAKE A LIST OF IMAGE FILE NAMES ###\n",
    "#######################################\n",
    "\n",
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/lobelia/binary_leaves/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ae0a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 10000\n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "lobeliacm_arr = np.zeros((len(lobelia_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(lobelia_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = lobelia_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(np.array(sorted_x_conts[0], dtype=np.float32), \n",
    "                                           np.array(sorted_y_conts[0], dtype=np.float32), high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((lobelia_mdata[\"base_x\"][lf], lobelia_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((lobelia_mdata[\"tip_x\"][lf], lobelia_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "    \n",
    "    # calculate leaf area in pixels^2\n",
    "    lf_area_px2 = poly_area(rot_pts[:,0], rot_pts[:,1])\n",
    "    \n",
    "    # get px_cm\n",
    "    px_cm = lobelia_mdata[\"px_cm\"][lf]\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(px_cm)\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    lobeliacm_arr[lf,:,:] = cm_lf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"lobelia_spp_cm_arr\", lobeliacm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeec08a",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389511db",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"coca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063e411",
   "metadata": {},
   "source": [
    "### *Erythroxylum coca*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeba94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoa_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/cocoa/cocoa.csv\") # read in csv\n",
    "\n",
    "cocoa_mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca467a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/cocoa/cultivated_images/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793dd805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 10000\n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "cocoa_cm_arr = np.zeros((len(cocoa_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(cocoa_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = cocoa_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(np.array(sorted_x_conts[0], dtype=np.float32), \n",
    "                                           np.array(sorted_y_conts[0], dtype=np.float32), high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((cocoa_mdata[\"base_x\"][lf], cocoa_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((cocoa_mdata[\"tip_x\"][lf], cocoa_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "    \n",
    "    # calculate leaf area in pixels^2\n",
    "    lf_area_px2 = poly_area(rot_pts[:,0], rot_pts[:,1])\n",
    "    \n",
    "    # get px_cm\n",
    "    px_cm = cocoa_mdata[\"px_cm\"][lf]\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(px_cm)\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    cocoa_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a947a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Erythroxylum_coca_cm_arr\", cocoa_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1aa14d",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d60f2a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"apple\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d93b64",
   "metadata": {},
   "source": [
    "### *Malus spp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a33241",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/apple/apple.csv\") # read in csv\n",
    "\n",
    "apple_mdata.head() # head data to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b2f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "### MAKE A LIST OF IMAGE FILE NAMES ###\n",
    "#######################################\n",
    "\n",
    "data_dir = \"/Volumes/TOSHIBA/collab_v3/apple/apple_images/\" # set data directory\n",
    "\n",
    "file_names = [f for f in listdir(data_dir) if isfile(join(data_dir, f))] # create a list of file names\n",
    "\n",
    "#file_names.remove('.DS_Store') # remove .DS_Store file\n",
    "\n",
    "file_names.sort() # sort the list of file names\n",
    "\n",
    "file_names # check list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c5561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### SET PARAMETERS ###\n",
    "######################\n",
    "\n",
    "# the number of equidistant points to create\n",
    "# an initial high resolution outline of the leaf\n",
    "high_res_pts = 10000\n",
    "\n",
    "# the ultimate number of equidistant points on each side of the leaf\n",
    "# (-1 for the tip)\n",
    "# the leaf will have res*2-1 pseudo-landmarks\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "res = 50 ########\n",
    "#################\n",
    "#################\n",
    "#################\n",
    "\n",
    "# an array to store pseudo-landmarks\n",
    "apple_cm_arr = np.zeros((len(apple_mdata),(res*2)-1,2))\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(apple_mdata)):\n",
    "\n",
    "    ###############################\n",
    "    ### READ IN GRAYSCALE IMAGE ###\n",
    "    ###############################\n",
    "\n",
    "    curr_image = apple_mdata[\"file\"][lf] # select the current image\n",
    "    print(lf, curr_image) # print each leaf in case there are problems later\n",
    "\n",
    "    # read in image\n",
    "    # convert to grayscale\n",
    "    # invert the binary\n",
    "    img = cv2.bitwise_not(cv2.cvtColor(cv2.imread(data_dir + curr_image),cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # find contours of binary objects\n",
    "    contours, hierarchy = cv2.findContours(img,  \n",
    "        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    ##############################\n",
    "    ### SELECT LARGEST CONTOUR ###\n",
    "    ##############################\n",
    "\n",
    "    # ideally there is only one leaf in the image\n",
    "    # in the case there are smaller objects\n",
    "    # this code selects the largest object (the leaf)\n",
    "    # if there is one and only one object in the image\n",
    "    # then the following code is not necessary\n",
    "\n",
    "    x_conts = [] # list of lists of contour x vals\n",
    "    y_conts = [] # list of lists of contour y vals\n",
    "    areas_conts = [] # list of bounding box areas of contours\n",
    "    for c in contours: # for each contour\n",
    "        x_vals = [] # store x vals for current contour \n",
    "        y_vals = [] # store y vals for current contour\n",
    "        for i in range(len(c)): # for each point in current contour\n",
    "            x_vals.append(c[i][0][0]) # isolate x val\n",
    "            y_vals.append(c[i][0][1]) # isolate y val\n",
    "        area = (max(x_vals) - min(x_vals))*(max(y_vals) - min(y_vals)) # calculate bounding box area of contour\n",
    "        x_conts.append(x_vals) # append the current contour x vals\n",
    "        y_conts.append(y_vals) # append the current contour y vals\n",
    "        areas_conts.append(area) # append the current contour bounding box areas\n",
    "\n",
    "    area_inds = np.flip(np.argsort(areas_conts)) # get indices to sort contours by area\n",
    "    sorted_x_conts = np.array(x_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, x vals\n",
    "    sorted_y_conts = np.array(y_conts, dtype=object)[area_inds][0:] # areas sorted largest to smallest, y vals\n",
    "\n",
    "    ################################################\n",
    "    ### INTERPOLATE HIGH RES NUMBER OF LANDMARKS ###\n",
    "    ################################################\n",
    "\n",
    "    # convert the leaf to high resolution number of landmarks\n",
    "    # using high_res_pt value\n",
    "    # need to convert arrays of pixel int to floats first\n",
    "    high_res_x, high_res_y = interpolation(np.array(sorted_x_conts[0], dtype=np.float32), \n",
    "                                           np.array(sorted_y_conts[0], dtype=np.float32), high_res_pts)\n",
    "\n",
    "    ###############################\n",
    "    ### FIND BASE AND TIP INDEX ###\n",
    "    ###############################\n",
    "\n",
    "    # get the base and tip landmark point values\n",
    "    base_pt = np.array((apple_mdata[\"base_x\"][lf], apple_mdata[\"base_y\"][lf]))\n",
    "    tip_pt = np.array((apple_mdata[\"tip_x\"][lf], apple_mdata[\"tip_y\"][lf]))\n",
    "\n",
    "    base_dists = [] # store distance of each high res point to base\n",
    "    tip_dists = [] # store distance of each high res point to tip\n",
    "\n",
    "    for pt in range(len(high_res_x)): # for each of the high resolution points\n",
    "\n",
    "        # euclidean distance of the current point from the base and tip landmark\n",
    "        ed_base = euclid_dist(base_pt[0], base_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "        ed_tip = euclid_dist(tip_pt[0], tip_pt[1], high_res_x[pt], high_res_y[pt])\n",
    "\n",
    "        # store distance of current point from base/tip\n",
    "        base_dists.append(ed_base)\n",
    "        tip_dists.append(ed_tip)\n",
    "\n",
    "    # get index of base and tip points\n",
    "    base_ind = np.argmin(base_dists)\n",
    "    tip_ind = np.argmin(tip_dists)\n",
    "\n",
    "    ################################\n",
    "    ### RESET BASE INDEX TO ZERO ###\n",
    "    ################################\n",
    "\n",
    "    # reset base index position to zero\n",
    "    high_res_x = np.concatenate((high_res_x[base_ind:],high_res_x[:base_ind]))\n",
    "    high_res_y = np.concatenate((high_res_y[base_ind:],high_res_y[:base_ind]))\n",
    "\n",
    "    # recalculate indices with new indexing\n",
    "    tip_ind = tip_ind-base_ind # note: negative index if tip_ind<base_ind\n",
    "    base_ind = base_ind-base_ind\n",
    "\n",
    "    # create single array for leaf coordinates\n",
    "    lf_contour = np.column_stack((high_res_x, high_res_y))\n",
    "\n",
    "    ##############################################################\n",
    "    ### INTERPOLATE EACH SIDE WITH DESIRED NUMBER OF LANDMARKS ###\n",
    "    ##############################################################\n",
    "\n",
    "    # interpolate at desired resolution the left and right sides of the leaf\n",
    "    left_inter_x, left_inter_y = interpolation(lf_contour[base_ind:tip_ind+1,0],lf_contour[base_ind:tip_ind+1,1],res)\n",
    "    right_inter_x, right_inter_y = interpolation(lf_contour[tip_ind:,0],lf_contour[tip_ind:,1],res)\n",
    "\n",
    "    # the start of the right side and end of the left side\n",
    "    # both contain the tip landmark\n",
    "    # delete the last point on the left side\n",
    "    left_inter_x = np.delete(left_inter_x, -1)\n",
    "    left_inter_y = np.delete(left_inter_y, -1)\n",
    "\n",
    "    # BASE OF LEAF IS INDEX 0\n",
    "    # TIP INDEX IS RES-1 IF BOTH LEFT & RIGHT POINTS\n",
    "    # TOTAL PSEUDOLANDMARKS IS 2*RES-1\n",
    "    lf_pts_left = np.column_stack((left_inter_x, left_inter_y))\n",
    "    lf_pts_right = np.column_stack((right_inter_x, right_inter_y))\n",
    "    lf_pts = np.row_stack((lf_pts_left, lf_pts_right))\n",
    "\n",
    "    ##########################################################\n",
    "    ### ROTATE LEAVES UPWARD AND SCALE SIZE TO CENTIMETERS ###\n",
    "    ##########################################################\n",
    "\n",
    "    tip_point = lf_pts[res-1,:] # get tip point\n",
    "    base_point = lf_pts[0,:] # get base point\n",
    "\n",
    "    # calculate angle between tip. base, and an arbitrary reference\n",
    "    ang = angle_between(tip_point, base_point, (base_point[0]+1,base_point[1]) )\n",
    "\n",
    "    # rotate points upwards\n",
    "    rot_x, rot_y = rotate_points(lf_pts[:,0], lf_pts[:,1], ang) \n",
    "    rot_pts = np.column_stack((rot_x, rot_y))\n",
    "    \n",
    "    # calculate leaf area in pixels^2\n",
    "    lf_area_px2 = poly_area(rot_pts[:,0], rot_pts[:,1])\n",
    "    \n",
    "    # get px_cm\n",
    "    px_cm = apple_mdata[\"px_cm\"][lf]\n",
    "\n",
    "    # scale leaf into cm\n",
    "    cm_lf = rot_pts/(px_cm)\n",
    "    \n",
    "    # store the leaf scaled into cm into the cm_arr\n",
    "    apple_cm_arr[lf,:,:] = cm_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"malus_spp_cm_arr\", apple_cm_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad5957",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec0978",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"combine_datasets\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde2fc5",
   "metadata": {},
   "source": [
    "## Section 4: Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd798008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack domesticated and wild arrays into one new array\n",
    "\n",
    "cm_arr = np.row_stack((capsella_cm_arr, arabidopsis_cm_arr, oak_cm_arr, lobeliacm_arr, \n",
    "                       cannibas_cm_arr, cocoa_cm_arr, apple_cm_arr, sugar_cm_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8701e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "capsella_cm_arr = np.load(\"capsella_cm_arr.npy\")\n",
    "arabidopsis_cm_arr = np.load(\"arabidopsis_cm_arr.npy\")\n",
    "oak_cm_arr = np.load(\"oak_cm_arr.npy\")\n",
    "lobeliacm_arr = np.load(\"lobeliacm_arr.npy\") \n",
    "cannibas_cm_arr = np.load(\"cannibas_cm_arr.npy\")\n",
    "cocoa_cm_arr = np.load(\"cocoa_cm_arr.npy\")\n",
    "apple_cm_arr = np.load(\"apple_cm_arr.npy\")\n",
    "sugar_cm_arr = np.load(\"sugar_cm_arr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in each dataset\n",
    "\n",
    "capsella_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/capsella/capsella.csv\") \n",
    "arabidopsis_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/arabidopsis/arabidopsis.csv\")\n",
    "oak_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/oak/oak.csv\")\n",
    "cannibas_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/cannibas/cannibas.csv\")\n",
    "lobelia_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/lobelia/lobelia.csv\")\n",
    "sugar_beets_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/sugar_beets/sugar_beets.csv\")\n",
    "cocoa_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/cocoa/cocoa.csv\")\n",
    "apple_data = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/apple/apple.csv\")\n",
    "\n",
    "# stack domesticated and wild genotypes into one new dataframe\n",
    "\n",
    "mdata = pd.concat([capsella_data, arabidopsis_data, oak_data, lobelia_data, cannibas_data, \n",
    "                        cocoa_data, apple_data, sugar_beets_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Volumes/TOSHIBA/collab_v3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99072aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata.to_csv('mdata_v1.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = pd.read_csv(\"/Volumes/TOSHIBA/collab_v3/mdata_v1.csv\") \n",
    "mdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493205c",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29bb923",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3a5dd",
   "metadata": {},
   "source": [
    "## Section 5: Procrustes Analysis and PCA\n",
    "\n",
    "Perform a Procrustes analysis to translate, scale, and rotate leaf shapes\n",
    "\n",
    "- Select number of pseudo-landmarks and dimensions\n",
    "- Calculate the GPA mean leaf shape using the `gpa_mean` function\n",
    "- Align all leaves to the GPA mean\n",
    "- Store Procrustes super-imposed leaves in an array, `proc_arr`\n",
    "- Calculate a PCA for all possible axes and their variance (the number of leaves)\n",
    "- Calculate a PCA for just the axes needed for reconstruction of eigenleaves for morphospace (probably 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff10156",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b421022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landmark_num = (res*2)-1 # select number of landmarks\n",
    "dim_num = 2 # select number of coordinate value dimensions\n",
    "\n",
    "##########################\n",
    "### CALCULATE GPA MEAN ###\n",
    "##########################\n",
    "\n",
    "mean_shape = gpa_mean(cm_arr, landmark_num, dim_num)\n",
    "\n",
    "################################\n",
    "### ALIGN LEAVES TO GPA MEAN ###\n",
    "################################\n",
    "\n",
    "# array to store Procrustes aligned shapes\n",
    "proc_arr = np.zeros(np.shape(cm_arr)) \n",
    "\n",
    "for i in range(len(cm_arr)):\n",
    "    s1, s2, distance = procrustes(mean_shape, cm_arr[i,:,:]) # calculate procrustes adjusted shape to ref for current leaf\n",
    "    proc_arr[i] = s2 # store procrustes adjusted shape to array\n",
    "    \n",
    "#################################################\n",
    "### FIRST, CALCULATE PERCENT VARIANCE ALL PCs ###\n",
    "#################################################\n",
    "\n",
    "######\n",
    "PC_NUMBER = np.shape(proc_arr)[1] # PC number = number of leaves\n",
    "#######\n",
    "\n",
    "# use the reshape function to flatten to 2D\n",
    "flat_arr = proc_arr.reshape(np.shape(proc_arr)[0], \n",
    "                                 np.shape(proc_arr)[1]*np.shape(proc_arr)[2]) \n",
    "\n",
    "pca_all = PCA(n_components=2) \n",
    "PCs_all = pca_all.fit_transform(flat_arr) # fit a PCA for all data\n",
    "\n",
    "# print out explained variance for each PC\n",
    "print(\"PC: \" + \"var, \" + \"overall \") \n",
    "for i in range(len(pca_all.explained_variance_ratio_)):\n",
    "    print(\"PC\" + str(i+1) + \": \" + str(round(pca_all.explained_variance_ratio_[i]*100,1)) + \n",
    "          \"%, \" + str(round(pca_all.explained_variance_ratio_.cumsum()[i]*100,1)) + \"%\"  )\n",
    "\n",
    "#################################################\n",
    "### NEXT, CALCULATE THE DESIRED NUMBER OF PCs ###\n",
    "#################################################\n",
    "\n",
    "######\n",
    "PC_NUMBER = 2 # PC number = 2, for limiting to 2 axes for morphospace reconstruction\n",
    "#######\n",
    "\n",
    "pca = PCA(n_components=PC_NUMBER) \n",
    "PCs = pca.fit_transform(flat_arr) # fit a PCA for only desired PCs\n",
    "\n",
    "# print out explained variance for each PC\n",
    "print(\"PC: \" + \"var, \" + \"overall \") \n",
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    print(\"PC\" + str(i+1) + \": \" + str(round(pca.explained_variance_ratio_[i]*100,1)) + \n",
    "          \"%, \" + str(round(pca.explained_variance_ratio_.cumsum()[i]*100,1)) + \"%\"  )\n",
    "    \n",
    "# add PCs to dataframe for plotting\n",
    "mdata[\"PC1\"] = PCs[:,0]\n",
    "mdata[\"PC2\"] = PCs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f886173",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39df3d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"save_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a28e62",
   "metadata": {},
   "source": [
    "## Section 6: Save pseudo-landmarked and Procrustes aligned leaves for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rotated leaves with pseudo-landmarks\n",
    "np.save('cm_arr', cm_arr)\n",
    "#save procurestes aligned leaves\n",
    "np.save('proc_arr', proc_arr)\n",
    "#save flattened procurestes aligned leaves\n",
    "np.save('flat_arr', flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec361b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "file_names = mdata['file']\n",
    "output_directory = './procurestes_files/'\n",
    "\n",
    "for name, row in zip(file_names, proc_arr):\n",
    "    filename = os.path.join(output_directory, f\"{name}.txt\")\n",
    "    np.savetxt(filename, row, fmt='%.6f') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f70798",
   "metadata": {},
   "source": [
    "When rerunning this jupyter notebook, it is faster to load the saved arrays that contain the pseudo-landmarks than to reprocess each species dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ec393",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_arr = np.load(\"cm_arr.npy\")\n",
    "proc_arr = np.load(\"proc_arr.npy\")\n",
    "flat_arr = np.load(\"flat_arr.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75179aaf",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd790a5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"leaf_measurements\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2dfeb",
   "metadata": {},
   "source": [
    "## Section 7: Analyze leaf dimensions\n",
    "Using placed pseudo-landmarks representing leaves that are rotated upwards and scaled in centimeters from `cm_arr`, calculate the following:\n",
    "\n",
    "- `width`: difference in centimeters between minimum and maximum x values in an oriented leaf\n",
    "- `length`: difference in centimeters between minimum and maximum y values in an oriented leaf\n",
    "- `area`: area of the leaf in centimeters squared\n",
    "- `solidity`: the ratio of area to convex hull area\n",
    "- `asymmetry`: the Procrustes distance between the superimposed left and right sides of a leaf outline. Lower values are more symmetric. Higher values are more asymmetric.  \n",
    "\n",
    "Data is stored in the `mdata` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store variables\n",
    "width_list = []\n",
    "length_list = []\n",
    "area_list = []\n",
    "solidity_list = []\n",
    "asymmetry_list = []\n",
    "\n",
    "# for each leaf . . .\n",
    "for lf in range(len(cm_arr)):\n",
    "    \n",
    "    # for calculating dimensions, we need non-scaled leaves in centimeters\n",
    "    curr_lf = cm_arr[lf,:,:] # select current leaf\n",
    "    \n",
    "    ############################\n",
    "    ### CALCULATE DIMENSIONS ###\n",
    "    ############################\n",
    "    \n",
    "    width = np.max(curr_lf[:,0])-np.min(curr_lf[:,0]) # calculate width\n",
    "    length = np.max(curr_lf[:,1])-np.min(curr_lf[:,1]) # calculate length\n",
    "    area = poly_area(curr_lf[:,0],curr_lf[:,1]) # calcualte area\n",
    "    \n",
    "    ##########################\n",
    "    ### CALCULATE SOLIDITY ###\n",
    "    ##########################\n",
    "    \n",
    "    hull = ConvexHull(curr_lf) # calculate convex hull of current leaf\n",
    "    vertices = hull.vertices # isolate vertex indices of convex hull\n",
    "    convex_area = poly_area(curr_lf[vertices,0], curr_lf[vertices,1]) # calculate convex area\n",
    "    solidity = area / convex_area # calculate solidity\n",
    "    \n",
    "    ##########################\n",
    "    ### CALCULATE SYMMETRY ###\n",
    "    ##########################\n",
    "    \n",
    "    left_side = curr_lf[:(res-1)+1,] # isolate left side of leaf\n",
    "    right_side = curr_lf[(res-1):,] # isolate right side of leaf\n",
    "    right_side = right_side[::-1] # reverse the right side to align indices with left\n",
    "\n",
    "    # calculate procrustes distance between left and right side of leaf\n",
    "    s1, s2, distance = procrustes(left_side, right_side) \n",
    "    \n",
    "    # store data in lists\n",
    "    width_list.append(width)\n",
    "    length_list.append(length)\n",
    "    area_list.append(area)\n",
    "    solidity_list.append(solidity)\n",
    "    asymmetry_list.append(distance)\n",
    "    \n",
    "# add data to the mdata dataframe\n",
    "mdata[\"width\"] = width_list\n",
    "mdata[\"length\"] = length_list\n",
    "mdata[\"area\"] = area_list\n",
    "mdata[\"solidity\"] = solidity_list\n",
    "mdata[\"asymmetry\"] = asymmetry_list\n",
    "\n",
    "#NOTE: run procurstes 1st \n",
    "circularity_vals = []\n",
    "aspect_ratio_vals = []\n",
    "\n",
    "# for each Procrustes-adjusted shape\n",
    "for i in range(np.shape(proc_arr)[0]):\n",
    "    \n",
    "    # select current shape\n",
    "    curr_shape = proc_arr[i] \n",
    "    \n",
    "    # calculate circularity and append to list\n",
    "    circularity_vals.append(Circularity(curr_shape))\n",
    "    \n",
    "    # calculate length, width, and aspect ratio\n",
    "    length = np.max(curr_shape[:,1]) - np.min(curr_shape[:,1])\n",
    "    width = np.max(curr_shape[:,0]) - np.min(curr_shape[:,0])\n",
    "    aspect_ratio_vals.append(width/length)\n",
    "    \n",
    "mdata['circ'] = circularity_vals\n",
    "mdata['ar'] = aspect_ratio_vals\n",
    "\n",
    "mdata.to_csv('metadata_v2.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea1893",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb124e5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pairplot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414db396",
   "metadata": {},
   "source": [
    "## Section 8: Explore data - Pairplot of all measured traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(mdata,\n",
    "             x_vars=[\"length\", \"width\", \"area\",\"circ\", \"ar\"],\n",
    "             y_vars=[\"length\", \"width\", \"area\",\"circ\", \"ar\"],\n",
    "             hue=\"dataset\",\n",
    "             plot_kws={\"s\": 100, \"alpha\":0.5, \"lw\":0}, \n",
    "            palette = custom_palette)\n",
    "\n",
    "plt.savefig('pair_plot_dataset_061125.png', dpi= 600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c76eb7",
   "metadata": {},
   "source": [
    "# Color palette <a class=\"anchor\" id=\"color_palette\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette = ['#602FF5', '#2FF5AD', '#F5532F', '#F5E32F', '#A06254', \n",
    "                 '#5A5175', '#517568', '#757251']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1b575",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"morphospace\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4933fa",
   "metadata": {},
   "source": [
    "## Section 9: Plotting PCA morphospace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3145103",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length= 20 # plot length in inches\n",
    "plot_width= 20 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"dataset\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"darkgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 1 # alpha of inverse eigenleaf\n",
    "pt_size = 100 # size of data points\n",
    "pt_linewidth = 0 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.8 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "#ax_tick_fs = 20 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "        \n",
    "sns.set_style(\"white\", {\"axes.grid\": False})  \n",
    "#xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "#ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "plt.savefig('dataset_morphospace_extended_darkgray.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e33fe",
   "metadata": {},
   "source": [
    "### Morphospace PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b26fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"dataset\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.5 # alpha of inverse eigenleaf\n",
    "pt_size = 25 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.50 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.8 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.scatterplot(data=mdata, x=\"PC1\", y=\"PC2\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_palette)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('combined_expanded_dataset_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b380a87",
   "metadata": {},
   "source": [
    "### PCA morphospace colored by circularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f035e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 1 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.scatterplot(data=mdata, x=\"PC1\", y=\"PC2\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('circ_dataset_061125_customcmap.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ef814",
   "metadata": {},
   "source": [
    "## custom continuous colormap <a class=\"anchor\" id=\"custom_color\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = [\"#9773F5\", \"#73A2F5\", \"#F5DA73\", \"#757161\", \"#676175\", \"#616975\"]\n",
    "custom_colors2 = [\"#F299DF\", \"#DBC7F2\", \"#E2F3C7\", \"#5C7337\", \"#733766\", \"#583D78\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c48350",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_gradient\", custom_colors)\n",
    "custom_cmap                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e899d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_cmap2 = LinearSegmentedColormap.from_list(\"custom_gradient\", custom_colors2)\n",
    "custom_cmap2                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92128664",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b023c6f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"plot_leaves\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ec9bf",
   "metadata": {},
   "source": [
    "## Section 10: Plotting real leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0358f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(cm_arr),50) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(5,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(cm_arr[i,:,0], cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(cm_arr[i,:,0])-0.1,min(cm_arr[i,:,0])-0.1],\n",
    "            [cm_arr[i,0,1], cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(cm_arr[i,:,0], cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(cm_arr[i,0,0], cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(cm_arr[i,res-1,0], cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    plt.title(mdata[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('leaves_pseudolandmarks_52.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e507c4a",
   "metadata": {},
   "source": [
    "### Plot leaves from individual datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ff507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(apple_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(apple_cm_arr[i,:,0], apple_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(apple_cm_arr[i,:,0])-0.1,min(apple_cm_arr[i,:,0])-0.1],\n",
    "            [apple_cm_arr[i,0,1], apple_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(apple_cm_arr[i,:,0], apple_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(apple_cm_arr[i,0,0], apple_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(apple_cm_arr[i,res-1,0], apple_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title(apple_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_apple_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(arabidopsis_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(arabidopsis_cm_arr[i,:,0], arabidopsis_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(arabidopsis_cm_arr[i,:,0])-0.1,min(arabidopsis_cm_arr[i,:,0])-0.1],\n",
    "            [arabidopsis_cm_arr[i,0,1], arabidopsis_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(arabidopsis_cm_arr[i,:,0], arabidopsis_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(arabidopsis_cm_arr[i,0,0], arabidopsis_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(arabidopsis_cm_arr[i,res-1,0], arabidopsis_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title(arabidopsis_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_arabidopsis.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb597e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(cannibas_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(cannibas_cm_arr[i,:,0], cannibas_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(cannibas_cm_arr[i,:,0])-0.1,min(cannibas_cm_arr[i,:,0])-0.1],\n",
    "            [cannibas_cm_arr[i,0,1], cannibas_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(cannibas_cm_arr[i,:,0], cannibas_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(cannibas_cm_arr[i,0,0], cannibas_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(cannibas_cm_arr[i,res-1,0], cannibas_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title(cannibas_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_cannibas_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(capsella_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(capsella_cm_arr[i,:,0], capsella_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(capsella_cm_arr[i,:,0])-0.1,min(capsella_cm_arr[i,:,0])-0.1],\n",
    "            [capsella_cm_arr[i,0,1], capsella_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(capsella_cm_arr[i,:,0], capsella_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(capsella_cm_arr[i,0,0], capsella_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(capsella_cm_arr[i,res-1,0], capsella_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title(capsella_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_capsella_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(cocoa_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(cocoa_cm_arr[i,:,0], cocoa_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(cocoa_cm_arr[i,:,0])-0.1,min(cocoa_cm_arr[i,:,0])-0.1],\n",
    "            [cocoa_cm_arr[i,0,1], cocoa_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(cocoa_cm_arr[i,:,0], cocoa_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(cocoa_cm_arr[i,0,0], cocoa_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(cocoa_cm_arr[i,res-1,0], cocoa_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title(cocoa_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_coca_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985fc22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(lobeliacm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(lobeliacm_arr[i,:,0], lobeliacm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(lobeliacm_arr[i,:,0])-0.1,min(lobeliacm_arr[i,:,0])-0.1],\n",
    "            [lobeliacm_arr[i,0,1], lobeliacm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(lobeliacm_arr[i,:,0], lobeliacm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(lobeliacm_arr[i,0,0], lobeliacm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(lobeliacm_arr[i,res-1,0], lobeliacm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title( lobelia_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_lobelia_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(oak_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(oak_cm_arr[i,:,0], oak_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(oak_cm_arr[i,:,0])-0.1,min(oak_cm_arr[i,:,0])-0.1],\n",
    "            [oak_cm_arr[i,0,1], oak_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(oak_cm_arr[i,:,0], oak_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(oak_cm_arr[i,0,0], oak_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(oak_cm_arr[i,res-1,0], oak_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title( oak_data[\"dataset\"][i], fontsize=13)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_oak_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbba02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random leaves and check that it is working\n",
    "\n",
    "plt.figure(figsize=(10,10)) # set figure size\n",
    "\n",
    "rand_indices = np.random.randint(0,len(sugar_cm_arr),10) # generate random indices of leaves\n",
    "\n",
    "plot_num = 1 # plot counter number\n",
    "\n",
    "for i in rand_indices:\n",
    "    \n",
    "    plt.subplot(1,10,plot_num) # subplot number\n",
    "    \n",
    "    plt.plot(sugar_cm_arr[i,:,0], sugar_cm_arr[i,:,1], c=\"k\", lw=0.1) # outline\n",
    "    plt.plot([min(sugar_cm_arr[i,:,0])-0.1,min(sugar_cm_arr[i,:,0])-0.1],\n",
    "            [sugar_cm_arr[i,0,1], sugar_cm_arr[i,0,1]+1], c=\"k\", lw=0.5) # cm scale\n",
    "    plt.scatter(sugar_cm_arr[i,:,0], sugar_cm_arr[i,:,1], c=\"k\", s=0.1) # points\n",
    "    plt.scatter(sugar_cm_arr[i,0,0], sugar_cm_arr[i,0,1], c = \"blue\", s=20) # base\n",
    "    plt.scatter(sugar_cm_arr[i,res-1,0], sugar_cm_arr[i,res-1,1], c= \"orange\", s=20) # tip\n",
    "    \n",
    "    #plt.title( sugar_beets_data[\"dataset\"][i], fontsize=12)\n",
    "    \n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plot_num += 1\n",
    "    \n",
    "#plt.suptitle(str(res*2-1) + \" pseudo-landmarks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('pseudolandmarks_sugarbeets_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707c726",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0df960",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"split_datasets\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df8223",
   "metadata": {},
   "source": [
    "## Section 11: Split datasets for further PCA morphospace plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce63a7",
   "metadata": {},
   "source": [
    "Here, you can modify the code to color the PCA morphospace by dataset, circularity, width, area, genotype, population, or any other dimension included in the mdata csv. Below are examples that color the PCA morphospace by circularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oak_df = mdata[mdata[\"dataset\"] == \"Quercus_spp\"]\n",
    "apple_df = mdata[mdata[\"dataset\"] == \"Malus_spp\"]\n",
    "lobelia_df = mdata[mdata[\"dataset\"] == \"Lobelia_spp\"]\n",
    "sugar_df = mdata[mdata[\"dataset\"] == \"B_vulgaris\"]\n",
    "capsella_df = mdata[mdata[\"dataset\"] == \"C_bursa_pastoris\"]\n",
    "cannabis_df = mdata[mdata[\"dataset\"] == \"C_sativa\"]\n",
    "arabidopsis_df = mdata[mdata[\"dataset\"] == \"A_thaliana\"]\n",
    "coca_df = mdata[mdata[\"dataset\"] == \"E_coca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3bd14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.scatterplot(data=oak_df, x=\"PC1\", y=\"PC2\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('oak_circ_061125_customcmap.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 100 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.scatterplot(data=oak_df, x=\"PC1\", y=\"PC2\", hue=hue, marker = \"*\", s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('apple_circ_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc549771",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 100 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.scatterplot(data=apple_df, x=\"PC1\", y=\"PC2\", hue=hue, marker = \"X\", s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('lobelia_circ_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.scatterplot(data=sugar_df, x=\"PC1\", y=\"PC2\", hue=hue, marker = \"P\", s=pt_size, linewidth=pt_linewidth, alpha=pt_alpha,\n",
    "               palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('sugar_circ_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b903c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.scatterplot(data=capsella_df, x=\"PC1\", y=\"PC2\", marker = \"s\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('capsella_circ_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67395774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.scatterplot(data=cannabis_df, x=\"PC1\", y=\"PC2\", marker = \"D\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('cannabis_circ_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d4c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 15 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.scatterplot(data=arabidopsis_df, x=\"PC1\", y=\"PC2\", marker = \"p\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('arabidopsis_circ_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc852f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_length= 10 # plot length in inches\n",
    "plot_width= 10 # plot length in inches\n",
    "numPC1 = 40 # set number of PC1 intervals\n",
    "numPC2 = 20 # set number of PC2 intervals\n",
    "hue = \"circ\" # select the factor to color by\n",
    "s = 0.06 # set the scale of the eigenleaves\n",
    "lf_col = \"lightgray\" # color of inverse eigenleaf\n",
    "lf_alpha = 0.9 # alpha of inverse eigenleaf\n",
    "pt_size = 50 # size of data points\n",
    "pt_linewidth = 1 # lw of data points, set to 0 for no edges\n",
    "pt_alpha = 0.80 # alpha of the data points\n",
    "ax_label_fs = 25 # font size of the x and y axis titles\n",
    "ax_tick_fs = 16 # font size of the axis ticks\n",
    "face_col = \"white\" # color of the plot background\n",
    "grid_alpha = 0.5 # set the alpha of the grid\n",
    "title = \"Procrustean morphospace colored by species\" # set title\n",
    "\n",
    "plt.figure(figsize=(plot_length, plot_width))\n",
    "\n",
    "PC1_vals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]), numPC1 ) # create PC intervals\n",
    "PC2_vals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), numPC2 )\n",
    "\n",
    "for i in PC1_vals: # for each PC1 interval\n",
    "    for j in PC2_vals: # for each PC2 interval\n",
    "        \n",
    "        pc1_val = i # select the current PC1 val\n",
    "        pc2_val = j # select the current PC2 val\n",
    "\n",
    "        # calculate the inverse eigenleaf\n",
    "        inv_leaf = pca.inverse_transform(np.array([pc1_val,pc2_val]))\n",
    "        inv_x = inv_leaf[0::2] # select just inverse x vals\n",
    "        inv_y = inv_leaf[1::2] # select just inverse y vals\n",
    "        \n",
    "        # plot the inverse eigenleaf\n",
    "        plt.fill(inv_x*s+pc1_val, inv_y*s+pc2_val, c=lf_col, alpha=lf_alpha)\n",
    "   \n",
    "# plot the data on top of the morphospace\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.scatterplot(data=coca_df, x=\"PC1\", y=\"PC2\", hue=hue, s=pt_size, linewidth=pt_linewidth, \n",
    "                alpha=pt_alpha, palette = custom_cmap2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.00, 1.02), prop={'size': 8.9})\n",
    "xlab = \"PC1, \" + str(round(pca.explained_variance_ratio_[0]*100,1)) + \"%\"\n",
    "ylab = \"PC2, \" + str(round(pca.explained_variance_ratio_[1]*100,1)) + \"%\"\n",
    "#plt.text(0.3, 0.28, \"rho = 0.67736\", horizontalalignment='left', size='medium', color='black')\n",
    "plt.xlabel(xlab, fontsize=ax_label_fs)\n",
    "plt.ylabel(ylab, fontsize=ax_label_fs)\n",
    "plt.xticks(fontsize=ax_tick_fs)\n",
    "plt.yticks(fontsize=ax_tick_fs)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.gca().set_facecolor(face_col)\n",
    "plt.grid(alpha=grid_alpha)\n",
    "plt.gca().set_axisbelow(True)\n",
    "\n",
    "\n",
    "plt.savefig('coca_circ_061325.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c14ed",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26d3f4",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"LDA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb97552",
   "metadata": {},
   "source": [
    "## Section 12: Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3595b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "### PERFORM LINEAR DISCRIMINANT ANALYSIS (LDA) ###\n",
    "##################################################\n",
    "\n",
    "# create a df for LDA by species\n",
    "species_df = pd.DataFrame(data=flat_arr[:,:])\n",
    "\n",
    "# add the genotype labels\n",
    "species_df[\"dataset\"] = mdata[\"dataset\"]\n",
    "\n",
    "# create input and output variables\n",
    "X = species_df.iloc[:,0:((res*2)-1)*2]\n",
    "y = species_df[\"dataset\"]\n",
    "\n",
    "# fit the LDA model\n",
    "species_model = LinearDiscriminantAnalysis()\n",
    "species_model.fit(X,y)\n",
    "\n",
    "# retrieve LDA scalings and coefficients\n",
    "species_scalings = species_model.scalings_\n",
    "species_coefs = species_model.coef_\n",
    "\n",
    "# perform prediction\n",
    "species_prediction= species_model.predict(X)\n",
    "comparison_result = [X == y for X, y in zip(y, species_prediction)]\n",
    "\n",
    "# print out number of correctly predicted results\n",
    "count_true_pl = comparison_result.count(True)\n",
    "count_false_pl = comparison_result.count(False)\n",
    "print(\"The number of falsely predicted:\", count_false_pl)\n",
    "print(\"The number of correctly predicted:\", count_true_pl)\n",
    "print(\"Out of \" + str(len(comparison_result)) + \" total samples\" )\n",
    "\n",
    "# Create confusion matrix\n",
    "true_species_values = mdata[\"dataset\"]\n",
    "predicted_species_values = species_prediction\n",
    "\n",
    "classes = sorted(mdata[\"dataset\"].unique())\n",
    "\n",
    "cm_species = confusion_matrix(true_species_values, predicted_species_values, labels=classes)\n",
    "\n",
    "\n",
    "## Define method to evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "#evaluate model\n",
    "scores = cross_val_score(species_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(\"model performed a mean accuracy of \", np.mean(scores))   \n",
    "\n",
    "# First subplot: confusion matrix\n",
    "sns.set(font_scale=1.4)\n",
    "ax1 = sns.heatmap(cm_species, annot=True, annot_kws={\"fontsize\":8.2}, fmt=\"d\", cmap=\"viridis\", square=True, cbar=False, xticklabels=classes, yticklabels=classes)\n",
    "ax1 = plt.title(\"Confusion matrix\")\n",
    "ax1 = plt.xlabel(\"Predicted class\", fontsize=15)\n",
    "ax1 = plt.ylabel(\"Actual class\", fontsize=15)\n",
    "\n",
    "sns.move_legend(ax2, \"upper left\", bbox_to_anchor=(1, 1), fontsize = 8.5)\n",
    "\n",
    "plt.savefig('lda_dataset_confusion_total_061325.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of linear discriminant scores by genotype\n",
    "\n",
    "data_plot = species_model.fit(X, y).transform(X)\n",
    "species_plot_df = pd.DataFrame(data=data_plot[:,:])\n",
    "species_plot_df[\"dataset\"] = mdata[\"dataset\"]\n",
    "\n",
    "species_plot_df = species_plot_df.rename(columns={0:'LD1', 1:'LD2', 2:\"LD3\", 3:\"LD4\", 4:\"LD5\", 5:\"LD6\"})\n",
    "\n",
    "fig, (ax4, ax5, ax6) = plt.subplots(ncols=3, sharey=True, figsize=(10,5))\n",
    "\n",
    "sns.scatterplot(data=species_plot_df, x=\"LD1\", y=\"LD2\", hue=\"dataset\", s=10, ax=ax4, palette = custom_palette)\n",
    "ax4.tick_params(axis='both', labelsize=15)\n",
    "ax4.set_xlabel(\"LD1\", fontsize=15)\n",
    "ax4.set_ylabel(\"LD2\", fontsize=15)\n",
    "ax4.get_legend().remove()\n",
    "sns.scatterplot(data=species_plot_df, x=\"LD3\", y=\"LD4\", hue=\"dataset\", s=10, ax=ax5, palette = custom_palette)\n",
    "ax5.tick_params(axis='both', labelsize=15)\n",
    "ax5.set_xlabel(\"LD3\", fontsize=15)\n",
    "ax5.set_ylabel(\"LD4\", fontsize=15)\n",
    "ax5.get_legend().remove()\n",
    "sns.scatterplot(data=species_plot_df, x=\"LD5\", y=\"LD6\", hue=\"dataset\", s=10, ax=ax6, palette = custom_palette)\n",
    "ax6.tick_params(axis='both', labelsize=15)\n",
    "ax6.set_xlabel(\"LD5\",fontsize=15)\n",
    "ax6.set_ylabel(\"LD6\", fontsize=15)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), fontsize = 8.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lda_panels_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe93f56",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efd10f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mean_leaf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afac6a",
   "metadata": {},
   "source": [
    "## Section 14: Plotting the mean leaf for the entire dataset and each species dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fd1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"dodgerblue\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('mean_leaf_v2.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf944453",
   "metadata": {},
   "source": [
    "### individual mean shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c200ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lobelia_mean = gpa_mean(lobeliacm_arr, landmark_num, dim_num)\n",
    "capsella_mean = gpa_mean(capsella_cm_arr, landmark_num, dim_num)\n",
    "arabidopsis_mean = gpa_mean(arabidopsis_cm_arr, landmark_num, dim_num)\n",
    "oak_mean = gpa_mean(oak_cm_arr, landmark_num, dim_num)\n",
    "cannabis_mean = gpa_mean(cannibas_cm_arr, landmark_num, dim_num)\n",
    "coca_mean = gpa_mean(cocoa_cm_arr, landmark_num, dim_num)\n",
    "apple_mean = gpa_mean(apple_cm_arr, landmark_num, dim_num)\n",
    "sugar_mean = gpa_mean(sugar_cm_arr, landmark_num, dim_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e081f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lobelia_mean[:,0], lobelia_mean[:,1], c = \"#F5E32F\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('lobelia_mean_leaf_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f700d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(lobelia_mean[:,0], lobelia_mean[:,1], \"#F5E32F\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('lobelia_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad21e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(capsella_mean[:,0], capsella_mean[:,1], \"#602FF5\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('capsella_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1dc5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(arabidopsis_mean[:,0], arabidopsis_mean[:,1], \"#2FF5AD\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('arabidopsis_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba1050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(oak_mean[:,0], oak_mean[:,1], \"#F5532F\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('oak_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89122ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(cannabis_mean[:,0], cannabis_mean[:,1], \"#A06254\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('cannabis_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c3749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(sugar_mean[:,0], sugar_mean[:,1], \"#757251\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('sugar_mean_leaf_v2\\\\overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f0ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(apple_mean[:,0], apple_mean[:,1], \"#517568\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('apple_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14e833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"black\", lw = 3)\n",
    "plt.fill(coca_mean[:,0], coca_mean[:,1], \"#5A5175\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('cocoa_mean_leaf_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9349fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(arabidopsis_mean[:,0], arabidopsis_mean[:,1], c = \"orange\", lw = 3)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('arabidopsis_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168dabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(cannabis_mean[:,0], cannabis_mean[:,1], c = \"purple\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('cannabis_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267a5da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(oak_mean[:,0], oak_mean[:,1], c = \"green\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('oak_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0117ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(capsella_mean[:,0], capsella_mean[:,1], c = \"darkblue\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('capsella_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d3107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(coca_mean[:,0], coca_mean[:,1], c = \"brown\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('coca_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d752e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(apple_mean[:,0], apple_mean[:,1], c = \"pink\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('apple_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5190444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sugar_mean[:,0], sugar_mean[:,1], c = \"gray\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('sugar_mean_leaf.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b186a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_col = \"k\" # set plot color\n",
    "a = 0.01 # set alpha\n",
    "for i in range(np.shape(proc_arr)[0]):\n",
    "    \n",
    "    curr_leaf = proc_arr[i,:,:]\n",
    "    \n",
    "    plt.plot(curr_leaf[:,0], curr_leaf[:,1], c=plot_col, alpha=a) # plot current leaf with color and alpha\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    \n",
    "plt.plot(mean_shape[:,0], mean_shape[:,1], c = \"dodgerblue\") # plot the mean leaf\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('mean_leaves_overlay_061125.png', dpi= 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310d5ce",
   "metadata": {},
   "source": [
    "[Back to top](#page_top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
